---
title: ""
output: 
  html_document: 
    css: in/boosh.css
---

<!-- first 5k in 35s (w 1500 sims) -->
<!-- this can be considered a "white box" system...  -->

We want to simulate a realistic scenario, but we also want to understand why it works the way it does. The approach that we will take is to start by simulating a very simplified scenario, and understanding precisely how it works and which factors it is sensitive to. Then, we will iteratively make the scenario more complicated, each time pausing to ensure we understand the influence of each added layer of abstraction. What we will end up with is a scenario that has all of the parameters and sources of variation as a genuine, lexical-decision based priming study, that uses accuracy and reaction time as dependent measures, and includes by-subject and by-item crossed random effects. 

  - [Step 0: replicate chemla sim](#step0)
  - [Step 1: run sims with an effect derived from literature](#step1)
  - [Step 2: introduce new analysis type(s)](#step2)
  - [Step 3: introduce by-subj random effect](#step3)
  - [Step 4: integrate with outlier introduction](#step4)
  - [Step 5: simulate case where artificial effect is observed](#step5)
  - [Step 6: simulate case where true effect is obscured](#step6)
  - [Step 7: write the abstract + submit :)](#step7)

```{r echo=TRUE}
# set default global chunk opts 
knitr::opts_chunk$set(
  message=FALSE, fig.width=6.24, fig.height=5, fig.show="hold"
)

# keep the environment slim until after sim runs and analysis
run_sim <- TRUE
if (!run_sim){
  packs <- c("dplyr","magrittr","reshape2","ggplot2","gridExtra")
  lefftpack::quiet_attach(packs)
}
source("noeffect_sims_functions.r")

# want to save results on this run?
save_res <- TRUE
```



#### Step 0: replicate chemla sim {#step0}

##### 0.1 set global parameters 

```{r}
# thresholds, regions, strategies to consider
thetas  <- c(0, .025, .05, .075, .1)
regions <- c("hi", "lo") # inactive
strats  <- c("exclude", "impute_theta", "impute_gmean", "impute_cmean") 

# total trials per dataset, and num simmed datasets
num_data_points <- 40
num_sims        <- 100

# grand mean and sd within each sim
grand_mu    <- 700
grand_sigma <- 100
```


##### 0.2 simulate data, store as `num_sims` $\times$ `num_data_points` matrix

```{r}
# simulate the experiment `num_sims` many times
sim_data <- nes_sim_data(num_sims, num_data_points, grand_mu, grand_sigma)
```


##### 0.3 set up analysis infrastructure 

```{r}
# df to hold individual sim results inside of loop
dat <- data.frame(
  data = numeric(num_data_points), 
  cond = rep(c("A","B"), each=num_data_points/2),
  stringsAsFactors=FALSE
)

# make a container to catch the sim results inside of loop
cont <- make_simshell(num_sims, thetas, strats)
```


##### 0.3alt set up sim for real data [chunk not visible and not executed]

```{r include=FALSE, eval=FALSE, echo=FALSE}
# use rt data from psycholing class
expfile <- "ignore/data/results-teaching_expt/results-nov22-clean.csv"
exp_dat <- read.csv(expfile, stringsAsFactors=FALSE)

# bad ones already tossed: table(exp_dat$correct, useNA="ifany")
# table(exp_dat$condition, useNA="ifany"); hist(exp_dat$RT)

# relabel the conditions we want to compare
cond_lkup <- c(cond_rel_word="A", cond_unr_word="B")

# build a df
dat <- data.frame(
  data = exp_dat$RT[exp_dat$condition %in% names(cond_lkup)],
  cond = cond_lkup[exp_dat$condition[exp_dat$condition %in% names(cond_lkup)]],
  stringsAsFactors=FALSE
)
# hyp is that A is faster/smaller than B


# thresholds, regions, strategies to consider
thetas  <- c(0, .025, .05, .075, .1)
regions <- c("hi", "lo") # inactive
strats  <- c("exclude", "impute_theta", "impute_gmean", "impute_cmean") 

# total trials per dataset, and num simmed datasets
num_data_points <- length(dat$data)
num_sims        <- 1

# grand mean and sd within each sim
grand_mu    <- mean(dat$data)
grand_sigma <- sd(dat$data)


# need to make sim_data and cont also

# make sim_data -- just a num_data_points*1 matrix since this is real data
sim_data <- matrix(dat$data, ncol=1)

# make cont -- just will have slots for one sim
cont <- make_simshell(num_sims=num_sims, thetas=thetas, strats=strats)

# reset dat since we're storing the real data in sim_data
dat <- data.frame(
  data = numeric(num_data_points), 
  cond = cond_lkup[exp_dat$condition[exp_dat$condition %in% names(cond_lkup)]],
  stringsAsFactors=FALSE
)

```


##### 0.4 analyze data and conduct hypothesis test at each simulation 

```{r}
### analyze the simulated data ---------------
for (x in seq_len(nrow(cont))){ # dev x=36
  # reset the data for whatever sim we're on 
  # (i.e. get rid of any changes from previous iteration)
  dat$data <- sim_data[, cont$sim[x]]
  
  # what is the difference in means for the raw simulated data
  cont$diffmeans_raw[x] <- 
    mean(dat$data[dat$cond=="A"]) - mean(dat$data[dat$cond=="B"])
  
  # values we're going to remove/treat as outliers
  trim_top <- dat$data[
    dat$data > quantile(dat$data, 1-cont$trim_top[x])
  ]
  trim_bot <- dat$data[
    dat$data < quantile(dat$data, cont$trim_bot[x])
  ]
  # record how many values we're treating as outliers
  # TODO: worry about the case where there's >1 point w a val in trim_*?!
  #     ~~~> Ã¥safer but slower way wd be: sum(dat$data %in% trim_top)
  cont$trimmed_top[x] <- length(trim_top) 
  cont$trimmed_bot[x] <- length(trim_bot)
  
  # also get all trimmed vals 
  trim <- c(trim_top, trim_bot)
  
  if (cont$strat[x]=="exclude"){
    # remove outlier data points by setting to NA
    dat$data[dat$data %in% trim] <- NA
  }
  if (cont$strat[x]=="impute_theta"){
    # toss outliers + impute by replacing w the appropriate threshold
    dat$data[dat$data %in% trim_top] <- 
      quantile(dat$data, 1-cont$trim_top[x], names=FALSE)
    dat$data[dat$data %in% trim_bot] <- 
      quantile(dat$data, cont$trim_bot[x], names=FALSE)
  }
  if (cont$strat[x]=="impute_gmean"){
    # toss outliers + impute by replacing w the grand mean
    dat$data[dat$data %in% trim] <- mean(dat$data[!dat$data %in% trim])
  }
  if (cont$strat[x]=="impute_cmean"){
    # toss outliers + replace each one w mean from their condition 
    for (condition in unique(dat$cond)){
      dat$data[dat$data %in% trim & dat$cond==condition] <- 
        mean(dat$data[!dat$data %in% trim & dat$cond==condition])
    }
    # TODO: generalize to "impute_bycol" so can do subj, item, cond, ... 
    # [easy: val=unique(cont[["imp_col"]]); for (val in vals)...]
  }
  # TODO: option to add noise of a certain kind, depending on $strat[x]
  # TODO: also impute by-subj mean + by-item mean
  # TODO: also impute w that one method in screencap
  
  
  # record meandiff after outliers have been transformed or removed (or not)
  cont$diffmeans_cut[x] <- 
    mean(dat$data[dat$cond=="A"], na.rm=TRUE) - 
    mean(dat$data[dat$cond=="B"], na.rm=TRUE)
  
  ### execute data analysis and conduct hypothesis test -----------------
  # TODO: swap to linear regression; eventually use mixed model; also anova
  # perform t-test
  res <- t.test(dat$data[dat$cond=="A"], dat$data[dat$cond=="B"])
  # record the results: tval, pval, ci
  # TODO: add standard error to output(??)
  cont$tval[x] <- unname(res$statistic)
  cont$pval[x] <- res$p.value 
  cont$confint[x] <- paste(round(res$conf.int, 3), collapse="||")
  
  # print a nice friendly message every 100 its <3
  if (x %% 100 == 0) message(paste0("okee done w iter ", x, " of ", nrow(cont)))
  
} # end loop; remove temp objects
rm(trim_top); rm(trim_bot); rm(res)
```


##### 0.5 post-process sim data and write it to disk

```{r}
# total data points per sim
cont$total_n <- num_data_points

# total data trimmed out per iteration
cont$trimmed_total <- cont$trimmed_top + cont$trimmed_bot

# whether data was trimmed at all in an iteration
cont$is_trimmed <- ifelse(cont$trimmed_total==0, FALSE, TRUE)

# recode strat of iterations whose data points were not trimmed
cont$strat <- ifelse(!cont$is_trimmed, "nothing", cont$strat)

# remove duplicate rows (shd be half of all strat=="nothing" rows)
cont <- cont[!duplicated(cont), ]

# write the sim data and analysis to disk if desired (switch at top)
if (save_res){
  outname <- get_fname(
    folder="out/", type="noeffect", 
    ftype="csv", nsim=num_sims, n=num_data_points, mean=grand_mu, sd=grand_sigma
  )
  write.csv(cont, outname, row.names=FALSE)
}
```


```{r}
# also load stuff if we didn't earlier (everything above here is base)
if (run_sim){
  packs <- c("dplyr","magrittr","reshape2","ggplot2","gridExtra")
  lefftpack::quiet_attach(packs)
}
# set plot theme
theme_set(theme_minimal(13))
```


##### 0.6 summarize results in tables  

```{r}
# define some useful subsets and list them up to iterate over
subsets <- list(
  trim_none    = cont[cont$trimmed_total == 0, ], 
  trim_top     = cont[cont$trimmed_top != 0 & cont$trimmed_bot == 0, ], 
  trim_bot     = cont[cont$trimmed_bot != 0 & cont$trimmed_top == 0, ], 
  trim_both    = cont[cont$trimmed_bot != 0 & cont$trimmed_top != 0, ],
  strat_excl   = cont[cont$strat=="exclude", ], 
  strat_imp_th = cont[cont$strat=="impute_theta",  ],
  strat_imp_gm = cont[cont$strat=="impute_gmean",  ],
  strat_imp_cm = cont[cont$strat=="impute_cmean",  ]
)

# "impute_theta", "impute_gmean", "impute_cmean"

# define some useful summary funcs for simulated p-vals
signifs <- function(df, pval_col="pval", alpha=.05){
  table(df[[pval_col]] < alpha)
}
prop_signif <- function(df, pval_col="pval", alpha=.05){
  round(mean(df[[pval_col]] < alpha), 4)
}
quant_at <- function(df, pval_col="pval", at=.05){
  round(quantile(df[[pval_col]], at), 3)
}
# also list them up to iterate over
foncs <- list(signifs=signifs, prop_signif=prop_signif, quant_at=quant_at)

# apply each fonc to each subset defined above
# to obtain an aggregate summary across the strategies + trimtypes
lapply(foncs, function(f){
  sapply(subsets, function(df) f(df))
})
```


```{r}
# summary over strategies
cont %>% group_by(strat) %>% summarize(
  nsim=n(), num_fp=sum(pval < .05), 
  prop_fp = num_fp / nsim, 
  se_fp = se_prop(p=prop_fp, n=nsim), 
  pval_quant05 = quantile(pval, probs=.05)
) %>% knitr::kable(digits=3, caption="summary of fp's over strategies")

# by-sim summary, getting best pval for each strat and sim
simsum <- cont %>% group_by(sim, strat) %>% summarize(
  lo_pval = min(pval), hi_pval = max(pval), mn_pval = mean(pval), 
  lo_p_tval = mean(tval[pval==min(pval)]), num_rows = n(), 
  # so we can compute which trimming values result in lowest pvals
  lo_pval_trimtop = trim_top[pval==min(pval)], 
  lo_pval_trimbot = trim_bot[pval==min(pval)], 
  lo_pval_trimtotal = trim_top[pval==min(pval)] + trim_bot[pval==min(pval)]
) %>% group_by(strat) %>% mutate(
  lo_p_strat_rank = rank(lo_pval)
) %>% ungroup() 

# grand means over strategies
grandmeans <- simsum %>% group_by(strat) %>% summarize(
  nsim = n(),
  num_fp = sum(lo_pval < .05),
  prop_fp = num_fp / nsim,
  se_fp = se_prop(p=prop_fp, n=nsim), 
  lo_pval_q05 = quantile(lo_pval, probs=.05, names=FALSE),
  mean_lo_pval = mean(lo_pval),
  sd_lo_pval = sd(lo_pval),
  mean_hi_pval = mean(hi_pval),
  sd_hi_pval = sd(hi_pval),
  mean_lo_p_tval = mean(lo_p_tval),
  sd_lo_p_tval = sd(lo_p_tval), 
  # compute most freq trim amounts for best pvals
  trimtop_mode = get_mode(lo_pval_trimtop), 
  ttopm_count = get_mode(lo_pval_trimtop, return_count=TRUE),
  trimbot_mode = get_mode(lo_pval_trimbot), 
  tbotmm_count = get_mode(lo_pval_trimbot, return_count=TRUE),
  trimtotal_mode = get_mode(lo_pval_trimtotal), 
  ttotalm_count = get_mode(lo_pval_trimtotal, return_count=TRUE)
)

capze <- c("grand means over strategies", 
           "what trim amount is most associated with the best pval")
knitr::kable(grandmeans[,c(1:10)], digits=3, caption=capze[1])
knitr::kable(grandmeans[,c(1:4,11:15)], digits=3, caption=capze[2])
rm(capze)
```


##### 0.7 summarize results in plots 

```{r}
# just look at the plots now
knitr::opts_chunk$set(echo=FALSE, message=TRUE)
```


```{r message=TRUE}
# record params in filenames when saving plots
titskel <- gsub(
  "\\.|sim_results-", "", get_fname(
    folder="", ftype="", 
    nsim=num_sims, n=num_data_points, mean=grand_mu, sd=grand_sigma
  )
)

tit <- "false discovery rate for each strategy"
ggplot(grandmeans, aes(x=strat, y=prop_fp, color=strat)) + 
  geom_bar(stat="identity",position="dodge",fill="transparent") + 
  geom_errorbar(
    aes(x=strat, ymin=prop_fp-se_fp, ymax=prop_fp+se_fp), 
    position="dodge", width=0
  ) + 
  geom_text(
    aes(x=strat, y=0, color=strat, label=unique(grandmeans$strat)), vjust=-.5
  ) + 
  theme(panel.grid.minor=element_blank(), panel.grid.major.x=element_blank(),
        legend.position="none", axis.text.x=element_blank()) + 
  labs(x="", y="", title=tit, 
       subtitle="proportion sims where best pval < .05 (+/- bootstrap se)")
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))


tit <- "best p-values against ranks, within strategy"
simsum %>% 
  ggplot(aes(x=lo_p_strat_rank, y=lo_pval, color=strat)) + 
    scale_shape_discrete(solid=FALSE) + 
    geom_point(alpha=.2) + theme(legend.position="top") + 
    labs(x="rank of best p-value", y="best p-value within strategy", title=tit)
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))
```


```{r message=TRUE}
tit <- "distribution of best p-values"
simsum %>% ggplot(aes(x=lo_pval, color=strat)) + 
  geom_histogram(binwidth=.05, fill="transparent") + 
  facet_wrap(~strat) + 
  theme(legend.position="top") + 
  labs(x="best p-value from individual sim run (binwidth = .05)", 
       title=tit, subtitle="for each strategy")
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))


tit <- "density estimate of best p-value dist"
simsum %>% ggplot(aes(x=lo_pval, fill=strat)) + 
  geom_density(alpha=.5) +
  theme(axis.text.y=element_blank()) + 
  theme(legend.position="top") + 
  labs(x="best p-value from individual sim run", 
       title=tit, subtitle="for each strategy")
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))
```


```{r message=TRUE}
# over-plotted? extra aggregation? 
# also wanna look at trimmed_total col of cont
# (note that `size=lo_p_tval` reveals no clear pattern)
tit <- "scat of pvals by strat"
ggplot(simsum, aes(x=sim, y=lo_pval, color=strat)) +
  geom_point(alpha=.5) + theme(legend.position="top") + 
  scale_shape_discrete(solid=FALSE) + 
  labs(title=tit, y="lowest p-val")
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))


tit <- "t-values against p-value ranks"
ggplot(simsum, aes(x=lo_p_strat_rank, y=lo_p_tval, color=strat)) +
  geom_point(alpha=.2) + theme(legend.position="top") + 
  scale_shape_discrete(solid=FALSE) + 
  labs(x="within-strategy best p-value, rank across sims", 
       y="t-value of x-axis p-val", 
       title=tit, subtitle="within each strategy")
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))
```



```{r}
tit <- "boxplots of p-val minima"
simsum %>% ggplot(aes(x=strat, y=lo_pval, color=strat)) + 
  geom_boxplot() + theme(legend.position="top") + 
  labs(x="", y="lowest p-val", title=tit)
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))

tit <- "boxplots of t-vals for p-val minima"
simsum %>% ggplot(aes(x=strat, y=lo_p_tval, color=strat)) + 
  geom_boxplot() + theme(legend.position="top") + 
  labs(x="", y="t-vals for lowest p-vals", title=tit)
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))
```



```{r message=TRUE}
tit <- "distribution of t-vals for best p-vals"
simsum %>% ggplot(aes(x=lo_p_tval, color=strat)) + 
  geom_histogram(binwidth=.1, fill="transparent") + 
  facet_wrap(~strat) + 
  theme(legend.position="top") + 
  labs(x="t-vals of best p-valuea by sim (binwidth = .1)", 
       title=tit, subtitle="for each strategy")
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))


tit <- "density estimate of t-val dist for best p-vals"
simsum %>% ggplot(aes(x=lo_p_tval, fill=strat)) + 
  geom_density(alpha=.5) +
  theme(axis.text.y=element_blank()) + 
  theme(legend.position="top") + 
  labs(x="t-val for best p-val from single sim run", 
       title=tit, subtitle="for each strategy")
# save it with params in filename
if (save_res) qsave(fname=paste0(tit, "_PARAMS_", titskel))

```


#### Step 1: run sims with an effect derived from literature {#step1}

<!-- ~/Google Drive/sandboxxxe/psycholing_discovery_sims/data/results-teaching_expt/results-nov22-clean.csv -->

or here is [link to rt data](data/results-teaching_expt/results-nov22-clean.csv) from psycholing last fall

#### Step 2: introduce new analysis type{s} {#step2}

#### Step 3: introduce by-subj random effect {#step3}

#### Step 4: integrate with outlier introduction {#step4}

#### Step 5: simulate case where artificial effect is observed {#step5}

#### Step 6: simulate case where true effect is obscured {#step6}

#### Step 7: write the abstract + submit :) {#step7}





```{r include=FALSE, echo=FALSE, eval=FALSE}
# timing info from july29: 
# # 3000 # 42:40 # 2000 17:45 # 1000 4:40

# # could use median too but unclear if wd give new info
# summ <- cont %>% group_by(sim, strat) %>% summarize(
#   min_p = min(pval), max_p = max(pval), mean_p = mean(pval), sd_p=sd(pval), 
#   mean_t = mean(tval), sd_t=sd(tval), n_rows = n()
# )
# # this is what it looks like
# summ %>% head(n=10) %>% knitr::kable(digits=4)


# arrange the two plots in a nice way
# g <- grid.arrange(pvals,tvals)

# write the plot to disk if desired
# if (save_res){
#   pnam <- paste0("out/sim_results_plot-", num_sims,"_sims-july29.pdf")
#   ggsave(g, filename=pnam, h=9, w=6, u="in")
# }

# ggplot(cont, aes(x=theta_bot, y=theta_top, MAKE A 3D SURFACE OF PVALS))


# not run
# View(dplyr::mutate_if(cont, is.numeric, round, digits=3))
# View(dplyr::mutate_if(summ, is.numeric, round, digits=3))

# summ %>% group_by(sim, is_trimmed) %>% summarize(
#   min_p = min(min_p),
#   max_p = max(max_p),
#   mean_mean_p = mean(mean_p),
#   mean_mean_t = mean(mean_t)
# ) %>% mutate_if(is.numeric, round, digits=3) 
```


